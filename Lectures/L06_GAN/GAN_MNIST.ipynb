{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-cradle",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-feeling",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-pricing",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch.nn import Sequential, Linear, ReLU, LeakyReLU, BatchNorm1d\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-sustainability",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-volume",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "if t.cuda.is_available():\n",
    "    if t.cuda.device_count()>1:\n",
    "        device = t.device('cuda:1')\n",
    "    else:\n",
    "        device = t.device('cuda')   \n",
    "else:\n",
    "    device = t.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-beast",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = t.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./data/mnist', train=True, download=True))\n",
    "\n",
    "dl_test  = t.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./data/mnist', train=False, download=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-socket",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mnist_train_data   = dl_train.dataset.data.to(dtype=t.float32)\n",
    "mnist_train_labels = dl_train.dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-robin",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mnist_test_data   = dl_test.dataset.data.to(dtype=t.float32)\n",
    "mnist_test_labels = dl_test.dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-republic",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mnist_data = np.concatenate((mnist_train_data, mnist_test_data))\n",
    "mnist_labels = np.concatenate((mnist_train_labels, mnist_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-headset",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "index=49\n",
    "plt.imshow(mnist_data[index], cmap='Greys')\n",
    "plt.text(22,3,'%d' % (mnist_labels[index],), fontsize=32);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-telephone",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mnist_data_flatened = 2*mnist_data.astype('float32').reshape(-1,28*28)/255.0 - 1.0\n",
    "np.random.shuffle(mnist_data_flatened)\n",
    "mnist_data_t = t.from_numpy(mnist_data_flatened[0:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-assignment",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "I am taking the whole data set. But if you run on the CPU you can consider using a smaller portion e.g \n",
    "```\n",
    "mnist_data_t = t.from_numpy(mnist_data_flatened[0:20000])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-heather",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-cover",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    if isinstance(layer,t.nn.modules.linear.Linear):\n",
    "        fan_in = layer.weight.size(1)\n",
    "        sigma = 1*np.sqrt(6/fan_in)\n",
    "        t.nn.init.uniform_(layer.weight,-sigma,sigma)\n",
    "        if layer.bias is not None:\n",
    "            t.nn.init.zeros_(layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-intake",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def init_layer_with_sigma(sigma=1):\n",
    "    def f(layer):\n",
    "        if isinstance(layer,t.nn.modules.linear.Linear):\n",
    "            fan_in = layer.weight.size(1)\n",
    "            s = sigma*np.sqrt(6/fan_in)\n",
    "            t.nn.init.uniform_(layer.weight, -s , s)\n",
    "            if layer.bias is not None:\n",
    "                t.nn.init.zeros_(layer.bias)\n",
    "    return f            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-master",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential(Linear(28*28,1024), \n",
    "                           LeakyReLU(0.2, inplace=True),\n",
    "                           t.nn.Dropout(0.3),\n",
    "                           Linear(1024,512), \n",
    "                           LeakyReLU(0.2, inplace=True),\n",
    "                           t.nn.Dropout(0.3),\n",
    "                           Linear(512,256), \n",
    "                           LeakyReLU(0.2, inplace=True),\n",
    "                           t.nn.Dropout(0.3),\n",
    "                           Linear(256,1), \n",
    "                           t.nn.Sigmoid()\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-trust",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(noise_input_size):\n",
    "    return Sequential( Linear(noise_input_size,256), BatchNorm1d(256), LeakyReLU(0.2, inplace=True),\n",
    "                       Linear(256,512),   BatchNorm1d(512), LeakyReLU(0.2, inplace=True),\n",
    "                       Linear(512,1024), BatchNorm1d(1024), LeakyReLU(0.2, inplace=True),\n",
    "                       Linear(1024,28*28), t.nn.Tanh()\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_input_size = 100\n",
    "generator = make_generator(noise_input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-secretary",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "discriminator.apply(init_layer_with_sigma(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-brake",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator.apply(init_layer_with_sigma(1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-cotton",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Move data and models to the device (CUDA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-knitting",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mnist_data_t = mnist_data_t.to(device)\n",
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-component",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with t.no_grad():\n",
    "    generator.eval()\n",
    "    in_t = t.empty(1,noise_input_size, device=device).uniform_(-1,1)\n",
    "    out_t = generator(in_t);\n",
    "    plt.imshow(out_t.data.cpu().numpy().reshape(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-demonstration",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Binary Cross Entropy loss with labels $l_i$ is defined as:\n",
    "$$bce(\\{ p_i \\},\\{ l_ i\\}) = \\frac{1}{n}\\sum_{i=0}^{n-1} \\left(l_i \\log p_i + (1-l_i) \\log(1-p_i)\\right)  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = t.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-humor",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Functions below implement a non-saturating loss function for generator and  one-sided label smoothing  for discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(imgs):\n",
    "    data_size = len(imgs)\n",
    "    \n",
    "    real_labels = t.ones(data_size,1, device=device)\n",
    "    d_real_loss = bce(discriminator(imgs), 0.9*real_labels) #Using one-sided label smoothing\n",
    "    fake_labels = t.zeros(data_size,1, device=device)\n",
    "    z = t.empty(data_size, noise_input_size, device=device).uniform_(-1,1)\n",
    "    g_out = generator(z).detach()\n",
    "    d_fake_loss = bce(discriminator(g_out), fake_labels)\n",
    "    \n",
    "    d_loss = d_fake_loss + d_real_loss\n",
    "    return d_loss \n",
    "    \n",
    "def generator_loss(data_size):    \n",
    "    z = t.empty(data_size, noise_input_size, device=device).uniform_(-1,1)\n",
    "    g_out = generator(z)\n",
    "    real_labels = t.ones(data_size,1, device=device)\n",
    "    g_loss = bce(discriminator(g_out), real_labels)\n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-guest",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with t.no_grad():\n",
    "              d_loss = discriminator_loss(mnist_data_t)\n",
    "              g_loss = generator_loss(len(mnist_data_t)) \n",
    "print(d_loss.item(), g_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-jones",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "d_optimizer = t.optim.Adam(discriminator.parameters(), lr=0.0004,betas=(0.5, 0.999))\n",
    "g_optimizer = t.optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-opening",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-increase",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "cols = 8\n",
    "rows = 4 \n",
    "\n",
    "fixed_noise = t.empty(cols*rows,noise_input_size, device=device).uniform_(-1,1)\n",
    "\n",
    "k_discriminator = 2\n",
    "k_generator = 1\n",
    "if device.type == 'cpu':\n",
    "    mini_batch_size=64\n",
    "else:\n",
    "    mini_batch_size=2048\n",
    "n_epochs = 200\n",
    "\n",
    "generator.train()\n",
    "\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    for k in range(len(mnist_data_t)//mini_batch_size):\n",
    "        for di in range(k_discriminator):\n",
    "            d_optimizer.zero_grad()\n",
    "            kr = np.random.randint(0,len(mnist_data_t)//mini_batch_size )\n",
    "            d_loss= discriminator_loss(mnist_data_t[kr*(mini_batch_size):(kr+1)*(mini_batch_size)])\n",
    "                             \n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "        for gi in range(k_generator):\n",
    "            g_optimizer.zero_grad()\n",
    "            g_loss = generator_loss(mini_batch_size)\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "    if epoch % 1 == 0:\n",
    "        clear_output(wait=True)\n",
    "        with t.no_grad():           \n",
    "            d_loss = discriminator_loss(mnist_data_t)\n",
    "            g_loss = generator_loss(len(mnist_data_t)) \n",
    "        end = time.time()\n",
    "        ellapsed = end - start\n",
    "        time_per_epoch = ellapsed/epoch\n",
    "        eta = time_per_epoch*(n_epochs-epoch)\n",
    "        print('%5d %6.2f %6.2f %6.2fs %6.2fs\\n' % (epoch, d_loss.item(), g_loss.item(), ellapsed, eta))\n",
    "        fig, ax = plt.subplots(rows, cols, figsize=(1.5*cols,1.5*rows))\n",
    "        with t.no_grad():\n",
    "            # Generate the row x cols samples always using same noise for each of them. \n",
    "            generator.eval()\n",
    "            out_t = generator(fixed_noise);\n",
    "            #Plot the samples on rows x cols grid. \n",
    "            for i, j in itertools.product(range(rows), range(cols) ):\n",
    "                ax[i,j].get_xaxis().set_visible(False)\n",
    "                ax[i,j].get_yaxis().set_visible(False)\n",
    "            for i, j in itertools.product(range(rows), range(cols)):    \n",
    "                ax[i,j].imshow(out_t[i*cols+j].cpu().data.numpy().reshape(28,28), cmap='Greys')  \n",
    "            plt.savefig(\"img/_%03d.png\" % (epoch,))\n",
    "            plt.close() #This prevents plt from displaying the picture in the notebook. \n",
    "            generator.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-prefix",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#save the generator\n",
    "t.save(generator.state_dict(),\"gan.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-sleeping",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#display the samples\n",
    "with t.no_grad():\n",
    "    # Generate the row x cols samples always using same noise for each of them. \n",
    "    generator.eval()\n",
    "    out_t = generator(fixed_noise);\n",
    "    #Plot the samples on rows x cols grid. \n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(1.5*cols,1.5*rows))\n",
    "    for i, j in itertools.product(range(rows), range(cols) ):\n",
    "        ax[i,j].get_xaxis().set_visible(False)\n",
    "        ax[i,j].get_yaxis().set_visible(False)\n",
    "    for i, j in itertools.product(range(rows), range(cols)):    \n",
    "        ax[i,j].imshow(out_t[i*cols+j].cpu().data.numpy().reshape(28,28), cmap='Greys')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-continent",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Display original data\n",
    "cols = 8\n",
    "rows = 4 \n",
    "fig, ax = plt.subplots(rows, cols, figsize=(1.5*cols,1.5*rows))\n",
    "for i, j in itertools.product(range(rows), range(cols) ):\n",
    "    ax[i,j].get_xaxis().set_visible(False)\n",
    "    ax[i,j].get_yaxis().set_visible(False)\n",
    "for i, j in itertools.product(range(rows), range(cols)):  \n",
    "    ax[i,j].imshow(mnist_data[np.random.randint(0,len(mnist_data))], cmap='Greys')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-stuart",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "A demonstration of how to load generator.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-revolution",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator_loaded = make_generator(noise_input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-qatar",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator_loaded.load_state_dict(t.load('gan.pt'))\n",
    "generator_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-headquarters",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator_loaded= generator_loaded.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-smoke",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "in_t = t.empty(1,noise_input_size, device=device).uniform_(-1,1)\n",
    "out_t = generator_loaded(in_t);\n",
    "plt.imshow(out_t.cpu().data.numpy().reshape(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-forwarding",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
